{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbformat_minor": 5,
      "pygments_lexer": "ipython3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "id": "setup-clone-drive",
      "metadata": {},
      "source": [
        "!git clone https://github.com/gbend22/Bioinformatics-Final-Assignment.git\n",
        "import sys\n",
        "sys.path.append('/content/Bioinformatics-Final-Assignment')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "EXPR_PATH      = \"/content/drive/MyDrive/tcga_RSEM_gene_fpkm.gz\"\n",
        "PHENOTYPE_PATH = \"/content/drive/MyDrive/tcga_phenotype.tsv.gz\"\n",
        "PC_URL  = \"https://raw.githubusercontent.com/CBIIT/TULIP/main/gene_lists/protein_coding_genes.txt\"\n",
        "PC_PATH = \"/content/drive/MyDrive/protein_coding_genes.txt\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "imports",
      "metadata": {},
      "source": [
        "from preprocessing import (\n",
        "    load_protein_coding_genes,\n",
        "    load_phenotype,\n",
        "    load_expression_data,\n",
        "    align_samples,\n",
        "    filter_to_tulip_types,\n",
        "    normalize_and_pad,\n",
        "    encode_labels,\n",
        "    split_data,\n",
        "    create_dataloaders,\n",
        ")\n",
        "from models import LSTMClassifier"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "load-data",
      "metadata": {},
      "source": [
        "pc_gene_ids = load_protein_coding_genes(PC_URL, PC_PATH)\n",
        "labels_full, primary_tumor_idx = load_phenotype(PHENOTYPE_PATH)\n",
        "expr_full = load_expression_data(EXPR_PATH, pc_gene_ids, primary_tumor_idx)\n",
        "expr, labels = align_samples(expr_full, labels_full, primary_tumor_idx)\n",
        "del expr_full"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "preprocess",
      "metadata": {},
      "source": [
        "expr, y_raw, labels = filter_to_tulip_types(expr, labels)\n",
        "X = normalize_and_pad(expr)\n",
        "del expr\n",
        "\n",
        "y, le, NUM_CLASSES = encode_labels(y_raw)\n",
        "NUM_GENES = X.shape[1]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "split-and-loaders",
      "metadata": {},
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
        "del X\n",
        "\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "create-model",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "SEQ_LEN    = 198\n",
        "INPUT_SIZE = NUM_GENES // SEQ_LEN\n",
        "PROJ_DIM   = SEQ_LEN * INPUT_SIZE\n",
        "\n",
        "model = LSTMClassifier(\n",
        "    num_genes   = NUM_GENES,\n",
        "    seq_len     = SEQ_LEN,\n",
        "    input_size  = INPUT_SIZE,\n",
        "    hidden_size = 128,\n",
        "    num_layers  = 2,\n",
        "    num_classes = NUM_CLASSES,\n",
        "    dropout     = 0.3,\n",
        ").to(device)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "training-loop",
      "metadata": {},
      "source": [
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
        "scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "\n",
        "EPOCHS              = 60\n",
        "EARLY_STOP_PATIENCE = 10\n",
        "\n",
        "best_val_acc     = 0.0\n",
        "patience_counter = 0\n",
        "train_losses     = []\n",
        "val_accs         = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out  = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds  = model(xb).argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total   += yb.size(0)\n",
        "    val_acc = correct / total\n",
        "    val_accs.append(val_acc)\n",
        "    scheduler.step(1 - val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch:3d} | Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_lstm.pt\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "evaluation",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_lstm.pt\"))\n",
        "model.eval()\n",
        "\n",
        "all_preds, all_true = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        preds = model(xb).argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_true.extend(yb.numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_true  = np.array(all_true)\n",
        "\n",
        "test_acc = np.mean(all_preds == all_true)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_true, all_preds, target_names=le.classes_, zero_division=0))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "visualization",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, color=\"steelblue\", linewidth=2)\n",
        "axes[0].set_xlabel(\"Epoch\");  axes[0].set_ylabel(\"Loss\")\n",
        "axes[0].set_title(\"LSTM \\u2014 Training Loss\");  axes[0].grid(True)\n",
        "\n",
        "axes[1].plot(val_accs, color=\"darkorange\", linewidth=2)\n",
        "axes[1].axhline(y=best_val_acc, color=\"red\", linestyle=\"--\",\n",
        "                label=f\"Best ({best_val_acc:.4f})\")\n",
        "axes[1].set_xlabel(\"Epoch\");  axes[1].set_ylabel(\"Accuracy\")\n",
        "axes[1].set_title(\"LSTM \\u2014 Validation Accuracy\")\n",
        "axes[1].legend();  axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lstm_training_curves.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "cm = confusion_matrix(all_true, all_preds)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"YlOrRd\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_,\n",
        "            linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "plt.xlabel(\"Predicted\", fontsize=13)\n",
        "plt.ylabel(\"Actual\",    fontsize=13)\n",
        "plt.title(\"LSTM \\u2014 Confusion Matrix\", fontsize=15)\n",
        "plt.xticks(rotation=45, ha=\"right\", fontsize=7.5)\n",
        "plt.yticks(rotation=0,  fontsize=7.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lstm_confusion_matrix.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "precision = precision_score(all_true, all_preds, average=None, zero_division=0)\n",
        "recall    = recall_score(   all_true, all_preds, average=None, zero_division=0)\n",
        "f1        = f1_score(       all_true, all_preds, average=None, zero_division=0)\n",
        "\n",
        "x_pos = np.arange(len(le.classes_))\n",
        "width = 0.27\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 7))\n",
        "ax.bar(x_pos - width, precision, width, label=\"Precision\", color=\"steelblue\")\n",
        "ax.bar(x_pos,         recall,   width, label=\"Recall\",    color=\"darkorange\")\n",
        "ax.bar(x_pos + width, f1,       width, label=\"F1 Score\",  color=\"seagreen\")\n",
        "\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(le.classes_, rotation=45, ha=\"right\", fontsize=7.5)\n",
        "ax.set_ylabel(\"Score\", fontsize=12)\n",
        "ax.set_title(\"LSTM \\u2014 Per-Class Precision / Recall / F1\", fontsize=14)\n",
        "ax.axhline(y=test_acc, color=\"red\", linestyle=\"--\", linewidth=1.2,\n",
        "           label=f\"Overall Acc ({test_acc:.4f})\")\n",
        "ax.legend(fontsize=11);  ax.set_ylim(0, 1.1);  ax.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lstm_per_class_metrics.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 3))\n",
        "sns.heatmap(f1.reshape(1, -1), annot=True, fmt=\".2f\", cmap=\"RdYlGn\",\n",
        "            vmin=0, vmax=1, xticklabels=le.classes_, ax=ax,\n",
        "            cbar_kws={\"shrink\": 0.6})\n",
        "ax.set_yticklabels([\"LSTM\"], fontsize=11)\n",
        "ax.set_xticklabels(le.classes_, rotation=45, ha=\"right\", fontsize=7.5)\n",
        "ax.set_title(\"LSTM \\u2014 Per-Class F1 Score\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lstm_f1_heatmap.png\", dpi=150)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "save-checkpoints",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "SAVE_DIR = \"/content/drive/MyDrive/lstm_checkpoints\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "checkpoint = {\n",
        "    \"model_state_dict\":     model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    \"best_val_acc\":         best_val_acc,\n",
        "    \"test_acc\":             float(test_acc),\n",
        "    \"train_losses\":         train_losses,\n",
        "    \"val_accs\":             val_accs,\n",
        "    \"hyperparams\": {\n",
        "        \"NUM_GENES\":    NUM_GENES,\n",
        "        \"PROJ_DIM\":     PROJ_DIM,\n",
        "        \"SEQ_LEN\":      SEQ_LEN,\n",
        "        \"INPUT_SIZE\":   INPUT_SIZE,\n",
        "        \"hidden_size\":  128,\n",
        "        \"num_layers\":   2,\n",
        "        \"dropout\":      0.3,\n",
        "        \"num_classes\":  NUM_CLASSES,\n",
        "    }\n",
        "}\n",
        "torch.save(checkpoint, os.path.join(SAVE_DIR, \"best_lstm_checkpoint.pt\"))\n",
        "\n",
        "np.savez(\n",
        "    os.path.join(SAVE_DIR, \"shared_splits.npz\"),\n",
        "    X_train=X_train, X_val=X_val, X_test=X_test,\n",
        "    y_train=y_train, y_val=y_val, y_test=y_test\n",
        ")\n",
        "\n",
        "np.save(os.path.join(SAVE_DIR, \"label_classes.npy\"), le.classes_)\n",
        "\n",
        "lstm_results = {\n",
        "    \"test_acc\":       float(test_acc),\n",
        "    \"best_val_acc\":   float(best_val_acc),\n",
        "    \"train_losses\":   np.array(train_losses),\n",
        "    \"val_accs\":       np.array(val_accs),\n",
        "    \"all_preds\":      all_preds,\n",
        "    \"all_true\":       all_true,\n",
        "    \"precision\":      precision,\n",
        "    \"recall\":         recall,\n",
        "    \"f1\":             f1,\n",
        "    \"classes\":        le.classes_,\n",
        "    \"num_params\":     sum(p.numel() for p in model.parameters()),\n",
        "}\n",
        "np.savez(os.path.join(SAVE_DIR, \"lstm_results.npz\"), **lstm_results)\n",
        "\n",
        "print(f\"LSTM Final Summary\")\n",
        "print(f\"Best Val Accuracy :{best_val_acc:.4f}\")\n",
        "print(f\"Test Accuracy:{test_acc:.4f}\")\n",
        "print(f\"Macro F1:{f1.mean():.4f}\")\n",
        "print(f\"Weighted F1:{np.average(f1, weights=[np.sum(all_true == i) for i in range(NUM_CLASSES)]):.4f}\")\n",
        "print(f\"Parameters:{lstm_results['num_params']:,}\")\n",
        "print(f\"Num Genes (input):{NUM_GENES}\")\n",
        "print(f\"Num Classes:{NUM_CLASSES}\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}
